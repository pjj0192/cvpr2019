<!DOCTYPE html>
<html>

<head>
<script src="https://docs.opencv.org/master/opencv.js" type="text/javascript"></script>
<script src="https://docs.opencv.org/master/utils.js" type="text/javascript"></script>

<script type='text/javascript'>
  cv['onRuntimeInitialized']=()=>{
    // Create a camera object.
    var output = document.getElementById('output');
    var camera = document.createElement("video");
    camera.setAttribute("width", 640);
    camera.setAttribute("height", 480);

    // Get a permission from user to use a camera.
    navigator.mediaDevices.getUserMedia({video: true, audio: false})
      .then(function(stream) {
      camera.srcObject = stream;
      camera.onloadedmetadata = function(e) {
        camera.play();
      };
    });

    // Open camera stream and start a capturing loop.
    var cap = new cv.VideoCapture(camera);
    var frame = new cv.Mat(camera.height, camera.width, cv.CV_8UC4);
    var frameBGR = new cv.Mat(camera.height, camera.width, cv.CV_8UC3);
    var net;

    function captureFrame() {
      var begin = Date.now();
      cap.read(frame);  // Read a frame from camera
      cv.cvtColor(frame, frameBGR, cv.COLOR_RGBA2BGR);
      var blob = cv.blobFromImage(frameBGR, 1, {width: 192, height: 144}, [104, 117, 123, 0]);
      // Visualize frame
      cv.imshow(output, frame);

      setTimeout(captureFrame, 0);
    };

    // Download models
    var utils = new Utils('');
    utils.createFileFromUrl("opencv_face_detector.prototxt", "opencv_face_detector.prototxt", () => {
      utils.createFileFromUrl("opencv_face_detector.caffemodel", "opencv_face_detector.caffemodel", () => {
        net = cv.readNet("opencv_face_detector.prototxt", "opencv_face_detector.caffemodel");
        captureFrame();
      });
    });
  };
</script>

</head>

<body>
  <canvas id="output" width=640 height=480 style="max-width: 100%"></canvas>
</body>

</html>
